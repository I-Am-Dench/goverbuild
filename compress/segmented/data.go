package segmented

import (
	"bytes"
	"compress/zlib"
	"encoding/binary"
	"fmt"
	"io"
)

const (
	DefaultChunkSize = 0x40000
	compressionLevel = zlib.BestCompression
)

var (
	dataSignature = append([]byte("sd0"), 0x01, 0xff)
	order         = binary.LittleEndian
)

// File type: [sd0]
//
// NOTE: Due to zlib implementation differences, [DataWriter]
// is NOT guaranteed to produce equivalent sd0 files as
// generated by NetDevil.
//
// [sd0]: https://docs.lu-dev.net/en/latest/file-structures/segmented.html#segmented-data-sd0
type DataWriter struct {
	chunkSize int

	baseWriter io.Writer
	zlibWriter *zlib.Writer

	buf bytes.Buffer

	bytesLeft       int
	compressedBytes int64
	wroteSignature  bool
}

func (w *DataWriter) flushChunk() (n int, err error) {
	if err := w.zlibWriter.Close(); err != nil {
		return 0, err
	}

	size := w.buf.Len()
	if err := binary.Write(w.baseWriter, order, uint32(size)); err != nil {
		return 0, err
	}
	n += 4

	if written, err := io.Copy(w.baseWriter, &w.buf); err != nil {
		return n, err
	} else {
		n += int(written)
	}

	w.zlibWriter.Reset(&w.buf)
	w.bytesLeft = w.chunkSize
	return n, nil
}

func (w *DataWriter) Write(p []byte) (n int, err error) {
	if !w.wroteSignature {
		w.wroteSignature = true
		if _, err := w.baseWriter.Write(dataSignature); err != nil {
			return 0, fmt.Errorf("sd0: writer: signature: %w", err)
		}
	}

	if len(p) == 0 {
		return 0, nil
	}

	data := p[:min(w.bytesLeft, len(p))]
	extra := p[len(data):]

	written, _ := w.zlibWriter.Write(data)
	n += written
	w.bytesLeft -= written

	if w.bytesLeft <= 0 {
		if written, err := w.flushChunk(); err != nil {
			return n, fmt.Errorf("sd0: writer: %w", err)
		} else {
			w.compressedBytes += int64(written)
		}
	}

	if len(extra) > 0 {
		if written, err := w.Write(extra); err != nil {
			return n, fmt.Errorf("sd0: writer: %w", err)
		} else {
			n += written
		}
	}

	return n, nil
}

func (w *DataWriter) BytesWritten() int64 {
	return w.compressedBytes + int64(len(dataSignature))
}

func (w *DataWriter) Close() error {
	if w.buf.Len() > 0 {
		if written, err := w.flushChunk(); err != nil {
			return fmt.Errorf("sd0: close: %w", err)
		} else {
			w.compressedBytes += int64(written)
		}
	}
	return nil
}

// Creates a new [DataWriter] with a given chunk size.
func NewDataWriterSize(w io.Writer, chunkSize int) *DataWriter {
	dw := &DataWriter{
		chunkSize:  chunkSize,
		baseWriter: w,
		bytesLeft:  chunkSize,
	}

	dw.zlibWriter, _ = zlib.NewWriterLevel(&dw.buf, compressionLevel)
	return dw
}

// Creates a new [DataWriter] with the DefaultChunkSize
func NewDataWriter(w io.Writer) *DataWriter {
	return NewDataWriterSize(w, DefaultChunkSize)
}

// File type: [sd0]
//
// [sd0]: https://docs.lu-dev.net/en/latest/file-structures/segmented.html#segmented-data-sd0
type DataReader struct {
	baseReader io.Reader
	zlibReader io.ReadCloser

	chunkSize uint32 // num compressed bytes
	bytesRead int64  // uncompressed bytes read
}

func (r *DataReader) Read(p []byte) (n int, err error) {
	if r.zlibReader == nil {
		if err = binary.Read(r.baseReader, order, &r.chunkSize); err != nil {
			if err == io.EOF {
				return 0, io.EOF
			}
			return 0, fmt.Errorf("sd0: read: %w", err)
		}

		r.zlibReader, err = zlib.NewReader(io.LimitReader(r.baseReader, int64(r.chunkSize)))
		if err != nil {
			return 0, fmt.Errorf("sd0: read: %w", err)
		}
	}

	n, err = r.zlibReader.Read(p)
	r.bytesRead += int64(n)

	if err == io.EOF {
		r.bytesRead = 0
		r.zlibReader = nil
		return n, nil
	}

	if err != nil {
		return n, fmt.Errorf("sd0: read: %w", err)
	}

	return n, nil
}

// Creates a new [DataReader]. NewDataReader returns an error
// if the function fails to verify the signature.
func NewDataReader(r io.Reader) (*DataReader, error) {
	sig := [5]byte{}
	if _, err := r.Read(sig[:]); err != nil {
		if err == io.EOF {
			err = io.ErrUnexpectedEOF
		}
		return nil, fmt.Errorf("sd0: read: signature: %w", err)
	}

	if !bytes.Equal(sig[:], dataSignature) {
		return nil, fmt.Errorf("sd0: read: invalid signature")
	}

	return &DataReader{
		baseReader: r,
	}, nil
}
